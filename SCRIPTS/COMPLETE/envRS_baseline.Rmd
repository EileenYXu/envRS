---
title: "ABCDv5.1 Baseline Scores"
output:
  html_notebook:
    toc: true
    toc_float:
      collapsed: false
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results = "asis")
library(tidyverse)
library(RColorBrewer)
library(glmnet)
library(kableExtra)
set.seed(2024)
```

```{r}
train = readRDS("G://users/eileen/ABCD/ABCD_Environmental_Risk/ABCDv5.1/DATA/baseline_traindat.rds") |> na.omit() #6079 individuals
test = readRDS("G://users/eileen/ABCD/ABCD_Environmental_Risk/ABCDv5.1/DATA/baseline_testdat.rds") |> na.omit() #1509

## scale and centre numeric variables
numcols = names(train)[lapply(train, is.numeric)==T]
train = train |> mutate_at(numcols, ~ c(scale(.)) )
test = test |> mutate_at(numcols, ~ c(scale(.)) )

## remove columns that are not used for training data and make interactions
x = train |> select(-src_subject_id, -race_ethnicity, -cbcl_internalising, -cbcl_dsm5_depress) |> data.matrix()

x_interact = x[,-grep("gender", colnames(x))] * as.numeric(train$gender)
colnames(x_interact) = paste0(colnames(x_interact), "_gender")

## remove columns not used in test data and make interactions
test_pred = test |> select(-src_subject_id, -race_ethnicity, -cbcl_internalising, -cbcl_dsm5_depress) |> data.matrix()

test_pred_interact = test_pred[,-grep("gender", colnames(test_pred))] * as.numeric(test$gender)
colnames(test_pred_interact) = paste0(colnames(test_pred_interact), "_gender")

## data for glm
preds = cbind(x, x_interact)
dep = train$cbcl_dsm5_depress
int = train$cbcl_internalising

testpreds = cbind(test_pred, test_pred_interact)
rm(x, x_interact, test_pred, test_pred_interact, numcols)
```

# Elastic net linear regression using 'glmnet'

80-20 training-test split. Training sample N=6079, test sample N=1509. Although glmnet standardises data by default, coefficients are returned on their original scales. To get standardised coefficients for applying to other data, I'm scaling the raw data before inputting to glmnet. 

## CBCL DSM5-oriented depression subscale

```{r}
depfit = cv.glmnet(x = preds, y = dep, nfolds = 10)
plot(depfit)
```


```{r results='hide'}
dep.print = print(depfit)

depfit_coef = coef(depfit, s = "lambda.1se") |> as.matrix()
depfit_min = coef(depfit, s = "lambda.min") |> as.matrix()

coef_dep = data.frame(
  preds = rownames(depfit_coef),
  beta.min = depfit_min[,1],
  beta.1se = depfit_coef[,1],
  out = rep("CBCL_depression", nrow(depfit_coef)),
  row.names = NULL
)
```

```{r}
dep.print |> kbl(digits = 3) |> kable_styling()
```

### Fit statistics

```{r}
train_min = assess.glmnet(depfit, newx = preds, newy = dep, s = "lambda.min")
train_1se = assess.glmnet(depfit, newx = preds, newy = dep, s = "lambda.1se")
test_min = assess.glmnet(depfit, newx = testpreds, newy = test$cbcl_dsm5_depress, s = "lambda.min")
test_1se = assess.glmnet(depfit, newx = testpreds, newy = test$cbcl_dsm5_depress, s = "lambda.min")

data.frame(sample = c("training", "training", "test", "test"),
           lambda = c("min", "1se", "min", "1se"),
           mse = c(train_min$mse, train_1se$mse, test_min$mse, test_1se$mse),
           mae = c(train_min$mae, train_1se$mae, test_min$mae, test_1se$mae)) |> 
  kbl(digits = 3) |> kable_styling() |> scroll_box()
```

### Plot predictions

```{r}
depRS_train = data.frame(
  cbcl_dep = dep,
  depRS.min = predict(depfit, newx = preds, s = "lambda.min"),
  depRS.1se = predict(depfit, newx = preds, s = "lambda.1se"),
  data = rep("train", times= length(dep))
)

depRS_test = data.frame(
  cbcl_dep = test$cbcl_dsm5_depress,
  depRS.min = predict(depfit, newx = testpreds, s = "lambda.min"),
  depRS.1se = predict(depfit, newx = testpreds, s = "lambda.1se"),
  data = rep("test", times = nrow(test))
)

depRS_dat = rbind(depRS_test, depRS_train) |> 
  pivot_longer(cols = c("lambda.min", "lambda.1se"), names_to = "lambda", values_to = "predicted")
```

```{r}
ggplot(depRS_dat, aes(y = cbcl_dep, x = predicted, colour = lambda)) +
  geom_smooth() +
  theme_bw() +
  facet_wrap(~data) +
  labs(x = "predicted depRS", y = "CBCL depression (scaled and centred)")
```


## CBCL internalising subscale

```{r}
intfit = cv.glmnet(x = preds, y = int, nfolds = 10)
plot(intfit)
```


```{r results='hide'}
int.print = print(intfit)

intfit_coef = coef(intfit, s = "lambda.1se") |> as.matrix()
intfit_min = coef(intfit, s = "lambda.min") |> as.matrix()

coef_int = data.frame(
  preds = rownames(intfit_coef),
  beta.min = intfit_min[,1],
  beta.1se = intfit_coef[,1],
  out = rep("CBCL_internalising", nrow(intfit_coef)),
  row.names = NULL
)
```

```{r}
int.print |> kbl(digits = 3) |> kable_styling()
```

### Fit statistics

```{r}
train_min = assess.glmnet(intfit, newx = preds, newy = int, s = "lambda.min")
train_1se = assess.glmnet(intfit, newx = preds, newy = int, s = "lambda.1se")
test_min = assess.glmnet(intfit, newx = testpreds, newy = test$cbcl_dsm5_depress, s = "lambda.min")
test_1se = assess.glmnet(intfit, newx = testpreds, newy = test$cbcl_dsm5_depress, s="lambda.min")

data.frame(sample = c("training", "training", "test", "test"),
           lambda = c("min", "1se", "min", "1se"),
           mse = c(train_min$mse, train_1se$mse, test_min$mse, test_1se$mse),
           mae = c(train_min$mae, train_1se$mae, test_min$mae, test_1se$mae)) |> 
  kbl(digits = 3) |> kable_styling() |> scroll_box()
```

### Plot predictions

```{r}
intRS_train = data.frame(
  cbcl_int = int,
  intRS.min = predict(intfit, newx = preds, s = "lambda.min"),
  intRS.1se = predict(intfit, newx = preds, s = "lambda.1se"),
  data = rep("train", times= length(int))
)

intRS_test = data.frame(
  cbcl_int = test$cbcl_internalising,
  intRS.min = predict(intfit, newx = testpreds, s = "lambda.min"),
  intRS.1se = predict(intfit, newx = testpreds, s = "lambda.1se"),
  data = rep("test", times = nrow(test))
)

intRS_dat = rbind(intRS_test, intRS_train) |> 
  pivot_longer(cols = c("lambda.min", "lambda.1se"), names_to = "lambda", values_to = "predicted")
```

```{r}
ggplot(intRS_dat, aes(y = cbcl_int, x = predicted, colour = lambda)) +
  geom_smooth() +
  theme_bw() +
  facet_wrap(~data) +
  labs(x = "predicted intRS", y = "CBCL internalising (scaled and centred)")
```

## Coefficients

beta.min = coefficients for lambda value that produces minimum mean cross-validated error
beta.1se = coefficients for lambda value that produces the most regularized model while keeping the cross-validated error within one standard error of the minimum.

```{r}
base_coefs = rbind(coef_int[-1,], coef_dep[-1,])

data.frame(predictor = coef_int[,1],
           dep_beta.min = coef_dep[,2],
           dep_beta.1se = coef_dep[,3],
           int_beta.min = coef_int[,2],
           int_beta.1se = coef_int[,3]) |> 
  kbl(digits=3) |> kable_styling() |> scroll_box()
```

### beta.min

```{r fig.height=20, fig.width=10}
ggplot(base_coefs, aes(x = out, y = preds, fill = beta.min)) +
  geom_tile(color = "white", lwd = 1, linetype = 1) +
  geom_text(aes(label = round(beta.min, 3)), color = "black", size = 12, size.unit = "pt") +
  scale_fill_gradient2(name = "Standardised\nBeta", low = "#2166AC", high = "#B2182B") +
  xlab(NULL) + ylab(NULL) +
  theme(panel.grid = element_blank(), panel.background = element_blank(), 
        axis.text = element_text(size = 12), legend.title = element_text(size=12))

#ggsave(filename = "G://users/eileen/ABCD/ABCD_Environmental_Risk/ABCDv5.1/OUTPUT/FIGS/baseline_coefs_all.svg",height = 400, width = 200, units = "mm")
```

### beta.1se

```{r fig.height=20, fig.width=10}
ggplot(base_coefs, aes(x = out, y = preds, fill = beta.1se)) +
  geom_tile(color = "white", lwd = 1, linetype = 1) +
  geom_text(aes(label = round(beta.1se, 3)), color = "black", size = 12, size.unit = "pt") +
  scale_fill_gradient2(name = "Standardised\nBeta", low = "#2166AC", high = "#B2182B") +
  xlab(NULL) + ylab(NULL) +
  theme(panel.grid = element_blank(), panel.background = element_blank(), 
        axis.text = element_text(size = 12), legend.title = element_text(size=12))
```

## Non-zero coefficients

### beta.min

```{r fig.width=10, fig.height=7}
base_coefs_sig = base_coefs %>% filter(abs(round(beta.min, 3))>0)

base_coefs_sig |> arrange(desc(beta.min)) |> kbl() |> kable_styling() |> scroll_box()

ggplot(base_coefs_sig, aes(x = out, y = preds, fill = beta.min)) +
  geom_tile(color = "white", lwd = 1, linetype = 1) +
  geom_text(aes(label = round(beta.min, 3)), color = "black", size = 12, size.unit = "pt") +
  scale_fill_gradient2(name = "Standardised\nBeta", low = "#2166AC", high = "#B2182B") +
  xlab(NULL) + ylab(NULL) +
  theme(panel.grid = element_blank(), panel.background = element_blank(), 
        axis.text = element_text(size = 12), legend.title = element_text(size=12))


#ggsave(filename = "G://users/eileen/ABCD/ABCD_Environmental_Risk/ABCDv5.1/OUTPUT/FIGS/baseline_coefs_1.svg",height = 140, width = 200, units = "mm")
```

### beta.1se

```{r fig.width=10, fig.height=7}
base_coefs_sig = base_coefs %>% filter(abs(round(beta.1se, 3))>0)

base_coefs_sig |> arrange(desc(beta.1se)) |> kbl() |> kable_styling() |> scroll_box()

ggplot(base_coefs_sig, aes(x = out, y = preds, fill = beta.1se)) +
  geom_tile(color = "white", lwd = 1, linetype = 1) +
  geom_text(aes(label = round(beta.1se, 3)), color = "black", size = 12, size.unit = "pt") +
  scale_fill_gradient2(name = "Standardised\nBeta", low = "#2166AC", high = "#B2182B") +
  xlab(NULL) + ylab(NULL) +
  theme(panel.grid = element_blank(), panel.background = element_blank(), 
        axis.text = element_text(size = 12), legend.title = element_text(size=12))
```

## Descriptives: Training

```{r results='asis'}
train = readRDS("G://users/eileen/ABCD/ABCD_Environmental_Risk/ABCDv5.1/DATA/baseline_traindat.rds") |> na.omit() #6079 individuals
test = readRDS("G://users/eileen/ABCD/ABCD_Environmental_Risk/ABCDv5.1/DATA/baseline_testdat.rds") |> na.omit() #1509

summarytools::dfSummary(train[,-1], round.digits = 3, valid.col = F, varnumbers = F, 
                        na.col = F, graph.col = F, labels.col = F, plain.ascii = F)
```

## Descriptives: Test

```{r}
summarytools::dfSummary(test[,-1], round.digits = 3, valid.col = F, varnumbers = F, 
                        na.col = F, graph.col = F, labels.col = F, plain.ascii = F)
```

